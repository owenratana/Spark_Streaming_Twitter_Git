{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d53905",
   "metadata": {},
   "source": [
    "# Popularity Analysis of K-Drama on Twitter live data based on Language Speaker using Spark Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8f8a6",
   "metadata": {},
   "source": [
    "import SparkContext and StreamingContext from PySpark Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a45ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d88cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de01cd",
   "metadata": {},
   "source": [
    "Create a SparkContext with Appname 'StreamingTwitterAnalysis'\n",
    "Setting LogLevel to ERROR. This will not print all logs which are INFO or WARN level\n",
    "Create Spark StreamingContext. 10 is the batch interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName='StreamingTwitterAnalysisKDrama', master='local[*]')\n",
    "sc.setLogLevel('ERROR')\n",
    "ssc = StreamingContext(sc, 10)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ddc1e",
   "metadata": {},
   "source": [
    "Connect to socket broker using ssc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da14bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "socket_stream = ssc.socketTextStream('127.0.0.1', 9880)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd47e7",
   "metadata": {},
   "source": [
    "window function parameter sets the window length. All the analysis will be done on Tweets stored for 60 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ba9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = socket_stream.window(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88596134",
   "metadata": {},
   "source": [
    "## Process the Stream:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dict = {'am': 'Amharic',\n",
    " 'de': 'German',\n",
    " 'ml': 'Malayalam',\n",
    " 'sk': 'Slovak',\n",
    " 'ar': 'Arabic',\n",
    " 'el': 'Greek',\n",
    " 'dv': 'Maldivian',\n",
    " 'sl': 'Slovenian',\n",
    " 'hy': 'Armenian',\n",
    " 'gu': 'Gujarati',\n",
    " 'mr': 'Marathi',\n",
    " 'ckb': 'Sorani Kurdish',\n",
    " 'eu': 'Basque',\n",
    " 'ht': 'Haitian Creole',\n",
    " 'ne': 'Nepali',\n",
    " 'es': 'Spanish',\n",
    " 'bn': 'Bengali',\n",
    " 'iw': 'Hebrew',\n",
    " 'no': 'Norwegian',\n",
    " 'sv': 'Swedish',\n",
    " 'bs': 'Bosnian',\n",
    " 'hi': 'Hindi',\n",
    " 'or': 'Oriya',\n",
    " 'tl': 'Tagalog',\n",
    " 'bg': 'Bulgarian',\n",
    " 'hi-Latn': 'Latinized Hindi',\n",
    " 'pa': 'Panjabi',\n",
    " 'ta': 'Tamil',\n",
    " 'my': 'Burmese',\n",
    " 'hu': 'Hungarian',\n",
    " 'ps': 'Pashto',\n",
    " 'te': 'Telugu',\n",
    " 'hr': 'Croatian',\n",
    " 'is': 'Icelandic',\n",
    " 'fa': 'Persian',\n",
    " 'th': 'Thai',\n",
    " 'ca': 'Catalan',\n",
    " 'in': 'Indonesian',\n",
    " 'pl': 'Polish',\n",
    " 'bo': 'Tibetan',\n",
    " 'cs': 'Czech',\n",
    " 'it': 'Italian',\n",
    " 'pt': 'Portuguese',\n",
    " 'zh-TW': 'Traditional Chinese',\n",
    " 'da': 'Danish',\n",
    " 'ja': 'Japanese',\n",
    " 'ro': 'Romanian',\n",
    " 'tr': 'Turkish',\n",
    " 'nl': 'Dutch',\n",
    " 'kn': 'Kannada',\n",
    " 'ru': 'Russian',\n",
    " 'uk': 'Ukrainian',\n",
    " 'en': 'English',\n",
    " 'km': 'Khmer',\n",
    " 'sr': 'Serbian',\n",
    " 'ur': 'Urdu',\n",
    " 'et': 'Estonian',\n",
    " 'ko': 'Korean',\n",
    " 'zh-CN': 'Simplified Chinese',\n",
    " 'ug': 'Uyghur',\n",
    " 'fi': 'Finnish',\n",
    " 'lo': 'Lao',\n",
    " 'sd': 'Sindhi',\n",
    " 'vi': 'Vietnamese',\n",
    " 'fr': 'French',\n",
    " 'lv': 'Latvian',\n",
    " 'si': 'Sinhala',\n",
    " 'cy': 'Welsh',\n",
    " 'ka': 'Georgian',\n",
    " 'lt': 'Lithuanian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(l, lang_dict):\n",
    "    if l not in lang_dict:\n",
    "        return None\n",
    "    else:\n",
    "        return lang_dict[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = lines.map(lambda l: mapping(l, lang_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = langs.filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267626b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3c761",
   "metadata": {},
   "source": [
    "## Process and Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "def process(spark, rdd, sns, plt):\n",
    "    if not rdd.isEmpty():\n",
    "        rdd = rdd.map(lambda c: Row(lang=c))\n",
    "        df = spark.createDataFrame(rdd)\n",
    "        df.createOrReplaceTempView('langs')\n",
    "        df = spark.sql('select lang, count(*) as tweets_count \\\n",
    "                        from langs \\\n",
    "                        group by lang \\\n",
    "                        order by tweets_count desc \\\n",
    "                        limit 10')\n",
    "        pd_df = df.toPandas()\n",
    "        sns.barplot(x='tweets_count', y='lang', data=pd_df)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs.foreachRDD(lambda rdd: process(spark, rdd, sns, plt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf414c0",
   "metadata": {},
   "source": [
    "## Starting Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3856b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc8257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da85f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2d2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
